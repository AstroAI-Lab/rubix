{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "import os\n",
    "os.environ['SPS_HOME'] = '/mnt/storage/annalena_data/sps_fsps'\n",
    "#os.environ['SPS_HOME'] = '/home/annalena/sps_fsps'\n",
    "#os.environ['SPS_HOME'] = '/Users/annalena/Documents/GitHub/fsps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fits files\n",
    "\n",
    "In this notebook we show, how you can store your mock datacube in a fits file, which is the common format in which are observational data handled. We firtss create a mock IFU cube by running the RUBIX pipeline, store it then in a fits file and then lod the data from the fits file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from rubix.core.pipeline import RubixPipeline\n",
    "\n",
    "# Define Illustris configuration\n",
    "config_illustris = {\n",
    "    \"pipeline\": {\"name\": \"calc_ifu\"},\n",
    "    \"logger\": {\"log_level\": \"DEBUG\", \"log_file_path\": None, \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"},\n",
    "    \"data\": {\n",
    "        \"name\": \"NihaoHandler\",\n",
    "        \"args\": {\n",
    "            \"particle_type\": [\"stars\", \"gas\"],\n",
    "            \"save_data_path\": \"data\",\n",
    "            \"snapshot\": \"1024\",\n",
    "        },\n",
    "        \"load_galaxy_args\": {\"reuse\": True, \"id\": \"g8.26e11\"},\n",
    "        \"subset\": {\"use_subset\": True, \"subset_size\": 4000},\n",
    "    },\n",
    "    \"simulation\": {\n",
    "        \"name\": \"NIHAO\",\n",
    "        \"args\": {\n",
    "            \"path\": '/mnt/storage/_data/nihao/nihao_classic/g8.26e11/g8.26e11.01024',\n",
    "            \"halo_path\": '/mnt/storage/_data/nihao/nihao_classic/g8.26e11/g8.26e11.01024.z0.000.AHF_halos',\n",
    "            \"halo_id\": 0,\n",
    "        },\n",
    "    },\n",
    "    \"output_path\": \"output\",\n",
    "    \"telescope\": {\"name\": \"MUSE\", \"psf\": {\"name\": \"gaussian\", \"size\": 5, \"sigma\": 0.6}, \n",
    "                  \"lsf\": {\"sigma\": 1.2}, \"noise\": {\"signal_to_noise\": 100, \"noise_distribution\": \"normal\"}},\n",
    "    \"cosmology\": {\"name\": \"PLANCK15\"},\n",
    "    \"galaxy\": {\"dist_z\": 0.3, \"rotation\": {\"type\": \"edge-on\"}},\n",
    "    \"ssp\": {\"template\": {\"name\": \"FSPS\"}, #\"Mastar_CB19_SLOG_1_5\"},\n",
    "            \"dust\": {\n",
    "            \"extinction_model\": \"Cardelli89\", #\"Gordon23\", \n",
    "            \"dust_to_gas_ratio\": 0.01, # need to check Remyer's paper\n",
    "            \"dust_to_metals_ratio\": 0.4, # do we need this ratio if we set the dust_to_gas_ratio?\n",
    "            \"dust_grain_density\": 3.5, # g/cm^3 #check this value\n",
    "            \"Rv\": 3.1,\n",
    "        },\n",
    "            },\n",
    "}\n",
    "\n",
    "\n",
    "# Run pipeline\n",
    "pipe = RubixPipeline(config_illustris)\n",
    "data = pipe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.stars.datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert luminosity to flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubix.spectra.ifu import convert_luminoisty_to_flux\n",
    "from rubix.cosmology import PLANCK15\n",
    "\n",
    "observation_lum_dist = PLANCK15.luminosity_distance_to_z(config_illustris[\"galaxy\"][\"dist_z\"])\n",
    "observation_z = config_illustris[\"galaxy\"][\"dist_z\"]\n",
    "pixel_size = 1.0\n",
    "fluxcube = convert_luminoisty_to_flux(data.stars.datacube, observation_lum_dist, observation_z, pixel_size)\n",
    "data.stars.datacube = fluxcube/1e-20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.stars.datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxcube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "data.stars.spectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "data.stars.spectra.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "import numpy as np\n",
    "plt.plot(np.linspace(1, 10, data.stars.spectra.shape[2]), data.stars.spectra[:,:750000,:].sum(axis=1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBVAL_SKIP\n",
    "datacube = data.stars.datacube\n",
    "\n",
    "img = datacube.sum(axis=2)\n",
    "plt.imshow(img, origin=\"lower\")\n",
    "plt.plot(12,12, 'ro')\n",
    "plt.plot(17,12, 'x', color=\"blue\")\n",
    "plt.plot(7,12, 'x', color=\"orange\")\n",
    "plt.colorbar()\n",
    "print(img.min(), img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "wave = pipe.telescope.wave_seq\n",
    "#plt.plot(wave, data.stars.datacube[12, 12, :], color=\"red\", label=\"Spectrum\")\n",
    "#plt.vlines(4861.333, 0, 3000, color='r', label=\"Hbeta=4861.333A\")\n",
    "#plt.vlines(4861.333*1.1, 0, 3000, color='y', label=\"line obs=Hbeta*(1+z)\")\n",
    "plt.plot(wave, data.stars.datacube[7, 12, :], color=\"orange\", label=\"Spectrum 7,12\")\n",
    "plt.plot(wave, data.stars.datacube[17, 12, :], color=\"blue\", label=\"Spectrum 17,12\")\n",
    "#plt.xlim(5300, 5400)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "wave = pipe.telescope.wave_seq\n",
    "#plt.plot(wave, data.stars.datacube[12, 12, :], color=\"red\", label=\"Spectrum\")\n",
    "plt.vlines(4861.333, 0, 10, color='r', label=\"Hbeta=4861.333A\")\n",
    "plt.vlines(4861.333*1.1, 0, 0.5, color='y', label=\"line obs=Hbeta*(1+z)\")\n",
    "plt.plot(wave, data.stars.datacube[14, 12, :], color=\"blue\", label=\"Spectrum 2,12\")\n",
    "plt.plot(wave, data.stars.datacube[10, 12, :], color=\"orange\", label=\"Spectrum 22,12\")\n",
    "plt.xlim(5300, 5400)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram of the velocities\n",
    "plt.hist(data.stars.velocity[0,:,2], bins=30, edgecolor='black')\n",
    "plt.xlabel('Velocity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Star Velocities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your data arrays are defined as follows:\n",
    "pixel_assignment = np.asarray(np.squeeze(data.stars.pixel_assignment))\n",
    "velocities = np.asarray(data.stars.velocity[0, :, 2])\n",
    "\n",
    "# Compute the sum of velocities and count per pixel using np.bincount\n",
    "sum_velocity = np.bincount(pixel_assignment, weights=velocities)\n",
    "counts = np.bincount(pixel_assignment)\n",
    "\n",
    "# Calculate mean velocity; note: division by zero is avoided if every pixel has at least one star.\n",
    "mean_velocity = sum_velocity / counts\n",
    "\n",
    "\n",
    "# If you know the pixel grid dimensions (for example, a square grid)\n",
    "n_pixels = len(mean_velocity)\n",
    "grid_size = int(np.sqrt(n_pixels))\n",
    "if grid_size * grid_size != n_pixels:\n",
    "    raise ValueError(\"The total number of pixels is not a perfect square; please specify the grid shape explicitly.\")\n",
    "\n",
    "# Reshape the mean_velocity into a 2D array for imshow\n",
    "velocity_map = mean_velocity.reshape((grid_size, grid_size))\n",
    "print(velocity_map[12,12])\n",
    "\n",
    "print(velocity_map[17,12]-velocity_map[7,12])\n",
    "# Plot the result\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(velocity_map, origin='lower', interpolation='nearest', cmap='seismic')\n",
    "plt.colorbar(label='Mean Velocity')\n",
    "plt.title('Mean Velocity per Pixel')\n",
    "plt.xlabel('X pixel index')\n",
    "plt.ylabel('Y pixel index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubix import config\n",
    "import jax.numpy as jnp\n",
    "SPEED_OF_LIGHT=config[\"constants\"][\"SPEED_OF_LIGHT\"]\n",
    "velocity = data.stars.velocity[0, :, 2]\n",
    "doppler = jnp.exp(velocity/SPEED_OF_LIGHT)\n",
    "print(doppler.min(), doppler.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store datacube in a fits file with header\n",
    "\n",
    "In RUBIX we implemented a function that automaticly takes the relevant information from the config and writes it into the header. Then the header and data are stored in a fits file. All is done with the store_fits function from the rubix.core.fits module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBVAL_SKIP\n",
    "from rubix.core.fits import store_fits\n",
    "\n",
    "store_fits(config_illustris, data, \"output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datacube from fits file\n",
    "\n",
    "We implemented a function to load a fits file. It is based on MPDAF, which is a package to handle MUSE IFU cubes. You can load your datacube by the following line and access all kind of information from the fitsfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBVAL_SKIP\n",
    "from rubix.core.fits import load_fits\n",
    "\n",
    "cube = load_fits(\"output/IllustrisTNG_id11_snap99_stars_subsetTrue.fits\") #if you use NIHAO, you have to insert the NIHAO fits file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBVAL_SKIP\n",
    "cube.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBVAL_SKIP\n",
    "cube.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBVAL_SKIP\n",
    "cube.primary_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBVAL_SKIP\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image1 = cube[0,:,:]\n",
    "\n",
    "plt.figure()\n",
    "image1.plot(colorbar='v', title = '$\\lambda$ = %.1f (%s)' %(cube.wave.coord(1000), cube.wave.unit))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
